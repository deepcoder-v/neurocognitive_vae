{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67658c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.signal import buttord, butter, filtfilt, freqz, decimate\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython import get_ipython  # Run magic functions from script\n",
    "ipython = get_ipython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chansets_new():\n",
    "    chans = np.arange(0, 128)\n",
    "    chans_del = np.array(\n",
    "        [56, 63, 68, 73, 81, 88, 94, 100, 108, 114, 49, 43, 48, 38, 32, 44, 128, 127, 119, 125, 120, 121, 126,\n",
    "         113, 117, 1, 8, 14, 21, 25]) - 1\n",
    "    chans = np.delete(chans, chans_del)\n",
    "    return chans\n",
    "\n",
    "reducedchans = chansets_new() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18421350",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_idx = np.arange(0, len(reducedchans), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_idx_dict = {}\n",
    "for i in range(len(reducedchans)):\n",
    "    channel = reducedchans[i]\n",
    "    idx = channel_idx[i]\n",
    "    channel_idx_dict[channel] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5df8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parietal channels to keep similar signs (+ or -) of weights across subjects\n",
    "poschans = np.array([30, 36, 41, 46])\n",
    "poschans = np.concatenate((poschans, np.arange(50, 55)))\n",
    "poschans = np.concatenate((poschans, np.arange(57, 101)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "poschans = [channel_idx_dict[channel] for channel in poschans if channel in channel_idx_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = ['s100', 's59', 's109', 's110']\n",
    "subjects = ['s59']\n",
    "subdes = 's59'\n",
    "snrlabels = ['low', 'med', 'high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70163a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(data, wind=range(0, 50)):\n",
    "    \"\"\"Simple function to baseline EEG data for ERP calculations\n",
    "\n",
    "    Inputs:\n",
    "    data - sample*channel*trial or sample*trial*channel EEG data\n",
    "    wind - subtracting the mean of this window to re-center EEG data\n",
    "\n",
    "    Outputs:\n",
    "    recentered - Re-centered EEG data\n",
    "    \"\"\"\n",
    "\n",
    "    baselines = np.squeeze(np.mean(data[wind, :, :], axis=0))\n",
    "    recentered = data - np.tile(baselines, (data.shape[0], 1, 1))\n",
    "\n",
    "    return recentered\n",
    "\n",
    "\n",
    "def epochsubset(data, newindex, lockindex=None):\n",
    "    \"\"\"Reepochs each epoch of EEG data by timelocking each epoch\n",
    "    \"i\" to \"newindex[i]\" with maximum window size available\n",
    "\n",
    "    Inputs:  \n",
    "    data - sample*channel*trial EEG data\n",
    "    newindex - Vector of length \"trial\"\n",
    "\n",
    "    Optional inputs:\n",
    "    lockindex - Sample in which newdata is timelocked\n",
    "                Default: nanmin(newindex)\n",
    "\n",
    "    Outputs:  \n",
    "    newdata - Re-timelocked EEG data          \n",
    "    lockindex - Sample in which newdata is timelocked\n",
    "    badtrials - Index of trials where newindex contained nans\n",
    "    \"\"\"\n",
    "\n",
    "    if lockindex is None:\n",
    "        lockindex = int(np.nanmin(newindex))\n",
    "\n",
    "    windsize = (np.shape(data)[0] - int(np.nanmax(newindex))) + int(lockindex)\n",
    "\n",
    "    newdata = np.zeros(\n",
    "        (int(windsize), int(np.shape(data)[1]), int(np.shape(data)[2])))\n",
    "\n",
    "    for t in range(0, np.size(newindex)):\n",
    "        if np.isfinite(newindex[t]):\n",
    "            begin_index = int(newindex[t]) - lockindex\n",
    "            end_index = windsize + begin_index\n",
    "            newdata[:, :, t] = data[begin_index: end_index, :, t]\n",
    "\n",
    "    badtrials = np.where(np.isnan(newindex))\n",
    "\n",
    "    return newdata, lockindex, badtrials\n",
    "\n",
    "\n",
    "# Data save and load locations\n",
    "mydata_dir = ''\n",
    "dataloc = mydata_dir + '/data/exp5data/subjects/training/{0}/{0}_allcleaned.npz'\n",
    "svd_saveloc = mydata_dir + '/data/exp5data/subjects/training/{0}/{1}/erp_svd_{0}_{1}_v5_khuong.mat'\n",
    "# svd_saveloc = '/data10/michael/pdm/exp5data/subjects/training/{0}/{1}/erp_svd_{0}_{1}_v6.mat'\n",
    "indxloc = mydata_dir + '/data/exp5data/subjects/training/{0}/{0}_traintestindx.npz'\n",
    "\n",
    "# Sessions\n",
    "sessions = []\n",
    "for i in range(1, 8):\n",
    "    sessions.extend(['ses%i' % i])\n",
    "\n",
    "# Percentage variance explained\n",
    "def perexp(s):\n",
    "    pexp = np.square(s) / float(np.sum(np.square(s)))\n",
    "    return pexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af30a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for subdes in subjects:\n",
    "    print('Loading data for subject %s...' % (subdes))\n",
    "    # Load EEG Data\n",
    "    data = np.load(dataloc.format(subdes))\n",
    "\n",
    "    sr = 1000.  # Make sure it is a floating point number\n",
    "\n",
    "#     print('Filtering data for subject %s...' % (subdes))\n",
    "#     filtered = butterfilt(data['eeg'], sr, passband=(\n",
    "#         1.0, 10.0), stopband=(0.25, 20.0))\n",
    "#     # filtered = butterfilt(data['eeg'], sr, passband=(\n",
    "#     #     1.0, 30.0), stopband=(0.25, 40.0), attenuation=(1.0,5.0))\n",
    "#     filtered2 = butterfilt(data['eeg'], sr, passband=(\n",
    "#         0.1, 4.0), stopband=(0.01, 8.0))\n",
    "\n",
    "\n",
    "    from makefilter import makefiltersos\n",
    "    import scipy.signal as signal\n",
    "    # low pass filter\n",
    "    sos, w, h = makefiltersos(sr, 45, 55)\n",
    "    filtdata = signal.sosfiltfilt(sos, data['eeg'], axis=0, padtype='odd')\n",
    "\n",
    "    # high pass filter\n",
    "    sos2, w2, h2 = makefiltersos(sr, 1, 0.25, gs=20)\n",
    "    filtdatahigh = signal.sosfiltfilt(sos2, filtdata, axis=0, padtype='odd')\n",
    "    filtered = filtdatahigh.copy()\n",
    "    \n",
    "\n",
    "    noiseonsets = data['noiseonsets']\n",
    "    noiseonsets[noiseonsets < 100] = np.nan\n",
    "    noiseonsets[noiseonsets > 1000] = np.nan\n",
    "    datart = data['rt']\n",
    "    datart[datart < 0] = np.nan\n",
    "\n",
    "    if any(data['session'] == 'missing'):\n",
    "        sestrack = np.where(data['session'] == 'missing')[0][0]\n",
    "        nantrials = np.zeros((480 * np.shape(data['session'])[0]), dtype=bool)\n",
    "        nantrials[np.arange(0, 480) + 480 * (sestrack)] = True\n",
    "        noiseonsets[nantrials] = np.nan\n",
    "        datart[nantrials] = np.nan\n",
    "\n",
    "    print('Finding cue-locked and response-locked EEG for subject %s...' % (subdes))\n",
    "    cue_eeg, cue_lockindex, cue_badtrials = epochsubset(\n",
    "        filtered, noiseonsets)\n",
    "    resp_eeg, resp_lockindex, resp_badtrials = epochsubset(\n",
    "        filtered, datart + 1250)\n",
    "\n",
    "    print('Removing baselines for subject %s...' % (subdes))\n",
    "    # Response interval, stimulus-locked\n",
    "    rint_eeg = baseline(filtered[1150:2250, :, :], wind=range(0, 100))\n",
    "\n",
    "    # Cue interval, stimulus-locked\n",
    "    cue_eeg = baseline(\n",
    "        cue_eeg[(cue_lockindex - 100):(cue_lockindex + 500), :, :], wind=range(0, 100))\n",
    "\n",
    "    # Response interval, response-locked\n",
    "    resp_eeg = baseline(\n",
    "        resp_eeg[(resp_lockindex - 1250):(resp_lockindex), :, :], wind=range(0, 100))\n",
    "\n",
    "    # Load training/test index\n",
    "    indx = np.load(indxloc.format(subdes))\n",
    "\n",
    "    # Trials to keep\n",
    "    keeptrials = np.union1d(np.where(np.isfinite(data['noiseonsets']))[0],\n",
    "                            np.where(np.sum(data['artifact'], axis=0) != 129)[0])\n",
    "    keeptrials = np.setdiff1d(keeptrials, cue_badtrials)\n",
    "    keeptrials = np.setdiff1d(keeptrials, resp_badtrials)\n",
    "\n",
    "    # Non-artifact training trials\n",
    "    traintrials = np.union1d(indx['train'], keeptrials)\n",
    "\n",
    "    sestrack = 0\n",
    "    for ses in sessions:\n",
    "        temptrials = np.intersect1d(\n",
    "            traintrials, np.arange(0, 480) + 480 * (sestrack))\n",
    "        temptrials2 = np.arange(0, 480) + 480 * (sestrack)\n",
    "        snrtrack = 0\n",
    "        svds = dict()  # Run SVD to extract single-trial estimates\n",
    "        for snr in np.array([0.5, 1.0, 2.0]):\n",
    "            print('Calculating weights for subject %s, session %s, %0.1f SNR...' % (subdes, ses, snr))\n",
    "            # Extract trials\n",
    "            snrtrials = np.where(data['snrvec'] == snr)\n",
    "\n",
    "            thesetrials = np.intersect1d(temptrials, snrtrials)\n",
    "            alltrials = np.intersect1d(temptrials2, snrtrials)\n",
    "\n",
    "            # Channels to keep\n",
    "            keepchans = np.squeeze(np.array(\n",
    "                np.where(np.logical_not(np.all(np.squeeze(data['artifact'][:, alltrials]), 1)))))\n",
    "\n",
    "            # Maintain same extraction across conditions, do this for 3 time-locked\n",
    "            # intervals\n",
    "            windows = ['rint', 'cue', 'resp']\n",
    "\n",
    "#             for w in np.arange(0, 3):\n",
    "            for w in np.arange(0, 1):\n",
    "                exec('tempeeg = %s_eeg' % windows[w])\n",
    "\n",
    "#                 ixgrid1 = np.ix_(np.arange(0, tempeeg.shape[0]),\n",
    "#                                  reducedchans, thesetrials)  # Use only training data for ERP\n",
    "                ixgrid2 = np.ix_(np.arange(0, tempeeg.shape[0]),\n",
    "                                 reducedchans, alltrials)  # Calculate single-trial ERPs in all data\n",
    "\n",
    "                erp = np.squeeze(np.mean(tempeeg[ixgrid2], axis=-1))\n",
    "\n",
    "                # Non-statistical SVD\n",
    "                print('Computing singular value decomposition of %s %s for window %s' % (\n",
    "                    subdes, ses, windows[w]))\n",
    "                u, s, v = np.linalg.svd(erp[150:275,:], full_matrices=0)\n",
    "#                 u, s, v = np.linalg.svd(erp, full_matrices=0)\n",
    "                # Flip weights in the first component\n",
    "                if np.sum(v[0, poschans]) < 0.:\n",
    "                    v[0, :] = -v[0, :]\n",
    "                    u[:, 0] = -u[:, 0]\n",
    "                    \n",
    "                svds['svd_%s_%s' %(windows[w], snrlabels[snrtrack])] = dict()\n",
    "                svds['svd_%s_%s' % (windows[w], snrlabels[snrtrack])]['erpinput'] = erp\n",
    "                svds['svd_%s_%s' %(windows[w], snrlabels[snrtrack])]['u'] = u\n",
    "                svds['svd_%s_%s' %(windows[w], snrlabels[snrtrack])]['s'] = s\n",
    "                svds['svd_%s_%s' % (windows[w], snrlabels[snrtrack])]['perexp'] = perexp(s)\n",
    "                svds['svd_%s_%s' %(windows[w], snrlabels[snrtrack])]['v'] = v\n",
    "\n",
    "                avfw = v[0, :]\n",
    "                erp_ = np.tensordot(tempeeg[ixgrid2], avfw, axes=(1, 0))\n",
    "                svds['svd0_%s_%s' %(windows[w], snrlabels[snrtrack])] = np.repeat([avfw], erp_.shape[-1], axis=0)\n",
    "                svds['st_erp_%s_%s' % (windows[w], snrlabels[snrtrack])] = erp_\n",
    "\n",
    "                svds['goodchans'] = keepchans + 1\n",
    "                \n",
    "                correct_ = data['correct'][alltrials]\n",
    "                correct_[correct_ == 0] = -1\n",
    "                svds['st_rt_%s_%s' % (windows[w], snrlabels[snrtrack])] = np.multiply(data['rt'][alltrials], correct_)\n",
    "\n",
    "                svds['full_eeg_%s_%s' % (windows[w], snrlabels[snrtrack])] = tempeeg[ixgrid2]\n",
    "                print('Component 1 of svd_%s_%s explained %0.3f%% variance' % (\n",
    "                    windows[w], snrlabels[snrtrack], perexp(s)[0]))\n",
    "\n",
    "            snrtrack += 1\n",
    "            \n",
    "        print(svd_saveloc.format(subdes, ses))\n",
    "        sio.savemat(svd_saveloc.format(subdes, ses), svds)\n",
    "        sestrack += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempeeg.shape, tempeeg[ixgrid2].shape, avfw.shape, len(ixgrid2), ixgrid2[0].shape, ixgrid2[1].shape, ixgrid2[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_dir = ''\n",
    "svd_saveloc = mydata_dir + '/data/exp5data/subjects/training/{0}/{1}/erp_svd_{0}_{1}_v5_khuong.mat'\n",
    "data_saveloc = mydata_dir + '/data/exp5data/subjects/training/{0}/{1}_train_{0}_{2}_khuong.npy'\n",
    "\n",
    "sessions = []\n",
    "for i in range(1, 8):\n",
    "    sessions.extend(['ses%i' % i])    \n",
    "\n",
    "snr_idx = []\n",
    "ses_erp, ses_rt, ses_eeg = [], [], []\n",
    "ses_v = []\n",
    "for snr in snrlabels:\n",
    "    for ses in sessions:\n",
    "        path = svd_saveloc.format(subdes, ses)\n",
    "        print(path)\n",
    "        ses_data = sio.loadmat(path)\n",
    "        ses_eeg.append(ses_data['full_eeg_rint_%s' %snr])\n",
    "        ses_erp.append(ses_data['st_erp_rint_%s' %snr])\n",
    "        ses_rt.append(ses_data['st_rt_rint_%s' %snr])\n",
    "        snr_idx.extend(ses_data['st_rt_rint_%s' %snr].shape[1]*[snr])\n",
    "        ses_v.append(ses_data['svd0_rint_%s' %snr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a3f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ses_rt_cat = np.hstack(ses_rt)[0]\n",
    "nan_pos = np.isnan(ses_rt_cat)\n",
    "ses_rt_cat = ses_rt_cat[~nan_pos] / 1000.\n",
    "snr_idx = np.array(snr_idx)[~nan_pos]\n",
    "ses_v0_cat = np.vstack(ses_v)[~nan_pos]\n",
    "\n",
    "ses_eeg_cat = np.concatenate(ses_eeg, axis=-1)[:1000,:]\n",
    "ses_eeg_cat = np.swapaxes(ses_eeg_cat, 0, -1)[~nan_pos]\n",
    "ses_eeg_cat = decimate(ses_eeg_cat, 4)\n",
    "\n",
    "print(ses_rt_cat.shape, ses_eeg_cat.shape, ses_v0_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264319f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(ses_eeg_cat, axis=0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for snr in snrlabels:\n",
    "    idx = snr_idx == snr\n",
    "    \n",
    "    trialfinal_train_v0, trialfinal_test_v0, trialfinal_train_eeg, trialfinal_test_eeg, \\\n",
    "    rt_train, rt_test = \\\n",
    "    train_test_split(ses_v0_cat[idx], ses_eeg_cat[idx], ses_rt_cat[idx], test_size=0.2, shuffle=True)\n",
    "    \n",
    "    eeg_avg = np.average(trialfinal_train_eeg)\n",
    "    eeg_std = np.std(trialfinal_train_eeg)\n",
    "    \n",
    "    trialfinal_train_eeg = np.array((trialfinal_train_eeg-eeg_avg) / eeg_std)\n",
    "    trialfinal_test_eeg = np.array((trialfinal_test_eeg-eeg_avg) / eeg_std)\n",
    "    \n",
    "\n",
    "    prefix = '/home/khuong/Projects/DDM-VAE-GAN/dataset'\n",
    "    with open('%s/v0_train_%s_%s.npy' % (prefix, subdes, snr), 'wb') as f:\n",
    "        np.save(f, trialfinal_train_v0)\n",
    "\n",
    "    with open('%s/eeg_train_%s_%s.npy' % (prefix, subdes, snr), 'wb') as f:\n",
    "        np.save(f, trialfinal_train_eeg)\n",
    "\n",
    "    with open('%s/rt_train_%s_%s.npy' % (prefix, subdes, snr), 'wb') as f:\n",
    "        np.save(f, rt_train)\n",
    "\n",
    "    with open('%s/v0_val_%s_%s.npy' % (prefix, subdes, snr), 'wb') as f:\n",
    "        np.save(f, trialfinal_test_v0)\n",
    "\n",
    "    with open('%s/eeg_val_%s_%s.npy' % (prefix, subdes, snr), 'wb') as f:\n",
    "        np.save(f, trialfinal_test_eeg)\n",
    "\n",
    "    with open('%s/rt_val_%s_%s.npy' % (prefix, subdes, snr), 'wb') as f:\n",
    "        np.save(f, rt_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
